#  Key parameters like `project_root_path` must be set correctly to reflect your project's setup.
[project]
project_root_path = /root/tod_system

[data]
arabic_data_path = ./data/Arabic
english_data_path = ./data/English
french_data_path = ./data/French
turkish_data_path = ./data/Turkish

[experiment]
task = agent
language = English
output_dir = ./output/llamacpp/English
seed = 1
dst_model_path =  ./models/ggml-model-q4_0.gguf
rg_model_path = ./models/ggml-model-q4_0.gguf
chat_format= llama-2

generation_max_length = 256

context_window = 2048
max_context_char_length = 20000
num_of_example = 0

# Main GPU to use.
main_gpu = 0
# Number of layers to offload to GPU. If -1, all layers are offloaded.
gpu_layers = -1